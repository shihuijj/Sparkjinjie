# 实验简介
本次实验涉及数据预处理、消息队列发送和接收消息、数据实时处理、数据实时推送和实时展示等数据处理全流程所涉及的各种典型操作，涵盖Linux、Spark、Kafka、Flask、Flask-SocketIO、Highcharts.js、sockert.io.js、PyCharm等系统和软件的安装和使用方法。通过本案例，将有助于大数据学习者综合运用大数据课程知识以及各种工具软件，实现数据全流程操作。

## 实验目的
1. 熟悉Linux系统、MySQL、Hadoop、Hive、Sqoop、Spark等系统和软件的安装和使用；
2. 了解大数据处理的基本流程；
3. 熟悉数据预处理方法；
4. 熟悉在不同类型数据库之间进行数据相互导入导出；
5. 熟悉使用JSP语言搭建动态Web工程；
6. 熟悉使用Spark MLlib进行简单的分类操作。

## 软件工具
- Linux14.04 64位
- MySQL
- Hadoop 2.7
- Hive
- Sqoop
- ECharts
- Eclipse
- Spark

## 软件总体概览
![0-1](https://kfcoding-static.oss-cn-hangzhou.aliyuncs.com/gitcourse-bigdata/0-1_20180420063710.010.jpg)

## 数据集
淘宝购物行为数据集 (5000万条记录，数据有偏移，不是真实的淘宝购物交易数据，但是不影响学习)

## 实验任务

- 安装关系型数据库 MySQL
- 安装大数据处理框架 Hadoop
- 安装数据仓库 Hive
- 安装 Sqoop
- 安装 Eclipse
- 安装 Spark
- 对文本文件形式的原始数据集进行预处理
- 把文本文件的数据集导入到数据仓库Hive中
- 对数据仓库Hive中的数据进行查询分析
- 使用Sqoop将数据从Hive导入MySQL
- 利用Eclipse搭建动态Web应用
- 利用ECharts进行前端可视化分析
- 利用Spark MLlib进行回头客行为预测

## 实验步骤概览
步骤零：实验环境准备

步骤一：本地数据集上传到数据仓库Hive

步骤二：Hive数据分析

步骤三：将数据从Hive导入到MySQL

步骤四:利用Spark预测回头客

步骤五：利用ECharts进行数据可视化分析